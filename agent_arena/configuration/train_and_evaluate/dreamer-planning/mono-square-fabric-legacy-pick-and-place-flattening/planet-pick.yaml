
device: "cuda:0"
update_steps: 100001
test_interval: 1000


batch_size: 50
sequence_size : 50
no_op: [0.5, 0.5, 0.5, 0.5]

size: [64, 64]
channels: 3
grayscale: False
dyn_hidden: 200
dyn_deter: 200
dyn_stoch: 30
units: 200
reward_layers: 2
num_actions: 4
act: "relu"
dyn_trans_layers: 1
dyn_discrete: 0
dyn_input_layers: 1
dyn_output_layers: 1
dyn_cell: 'gru'
cnn_depth: 32
encoder_kernels: [4, 4, 4, 4]
decoder_kernels: [5, 5, 6, 6]
# value_head: 'normal'
decoder_thin: True

dyn_std_act: 'softplus'
dyn_min_std: 0.1
dyn_rec_depth: 1
dyn_shared: False
dyn_mean_act: 'none'
dyn_temp_post: True
grad_heads: ['image', 'reward']
clip_rewards: 'identity'



# pred_discount: False
# discount_scale: 1.0
weight_decay: 0.0



reward_scale: 1.0
reward_gradient_stop: False
kl_scale: 1.0
kl_balance: 0.8
kl_free: 1.0
kl_forward: False

# Overshooting
overshooting_distance: 2
overshooting_kl_scale: 0.1
overshooting_kl_balance: 1.0
kl_overshooting_warmup: True
overshooting_kl_free: 1.0
overshooting_kl_forward: False
overshooting_reward_scale: 0.1
reward_overshooting_warmup: False
overshooting_observation_scale: 0


# Optmiser
model_lr: 1e-3
opt_eps: 1e-4
grad_clip: 1000
opt: 'adam'


# Loss
decoder_output_mode: 'deterministic'
reward_output_mode: 'deterministic'
reward_loss: 'mse' # Dreamer: 'nll'
decoder_loss: 'mse' # Dreamer: 'nll'


# Test
test_horizons: [1, 2, 4, 12]
action_horizon: 50
eval_episodes: 100

dataset: 
  name: 'mono-square-fabric-legacy-pick-and-place'
  params:
    num_episodes: 20000
    return_img_dim: [64, 64]
    cross_traj: True

transform:
  name: 'pick_and_place_transformer'
  params:
    device: "cuda:0"
    bit_depth: 5
    rgb_noise_var: 1.0
    random_rotation: True
    random_terminal: False
    rotation_degree: 90
    vertical_flip: True
    random_resize: False
    action_noise: 0.0

policy:
  name: 'rect_fabric_mpc_readjust_pick'
  params:
    action_lower_bound: -0.5
    action_upper_bound: 0.5

    candidates: 5000
    planning_horizon: 2
    iterations: 100
    action_dim: [1, 4]
    clip: True


    readjust_pick: True,
    readjust_pick_threshold: 0.1
    flatten_threshold: 0.92
    no_op: [0.5, 0.5, 0.5, 0.5]
    conservative_place: 1.0

    cost_fn: 'from_model'