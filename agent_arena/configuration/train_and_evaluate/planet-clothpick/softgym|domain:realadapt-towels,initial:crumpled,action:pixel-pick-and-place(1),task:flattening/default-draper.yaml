device: 'cuda:0'
train_mode: 'offline'

input_obs: "rgbd"
output_obs: "input_obs"

deterministic_latent_dim: 200
stochastic_latent_dim: 30
action_dim: 4
hidden_dim: 200
embedding_dim: 1024
min_std_dev: 0.1
activation: 'relu'
trans_layers: 1
input_obs_dim: [4, 64, 64]
output_obs_dim: [4, 64, 64]
encoder_batchnorm: False
encoder_residual: False
decoder_batchnorm: False
decoder_residual: False
no_op: [1, 1, 1, 1]
free_nats: 1
symlog: False

observation_scale: 1.0
reward_scale: 1.0
reward_gradient_stop: False
kl_balance: 0.8
kl_scale: 1.0
kl_balancing: True

overshooting_distance: 2  
kl_overshooting_scale: 0.1
kl_overshooting_warmup: True
kl_overshooting_balance: 1.0
reward_overshooting_scale: 0.1
reward_overshooting_warmup: False


optimiser_class: 'adam'
optimiser_params: 
  lr: 1e-3
  eps: 1e-4
grad_clip_norm: 1000

batch_size: 50
sequence_size: 50
total_update_steps: 50001
validation_interval: 5000
test_interval: 1000

refresh_init_state: False

action_output:
  pick_0: [0, 1]
  place_0: [2, 3]

transform:
  name: 'pick_and_place_transformer'
  params:
    img_dim: [64, 64]
    device: "cuda:0"
    # bit_depth: 5
    #rgb_noise_farcor: 1.0
    random_rotation: True
    random_terminal: False
    remap_image: [0, 1]
    rgb_noise_factor: 0.02
    rotation_degree: 1
    vertical_flip: True
    random_resize: False
    action_noise: 0.0

    depth_clip: True
    depth_clip_min: 0.62 #
    depth_clip_max: 0.66 #0.66
    min_max_norm: True
    depth_min: 0.62
    depth_max: 0.66
    depth_map: True
    depth_map_range: [0, 1]
    depth_blur: True
    depth_flip: True
    depth_blur_kernel_size: 5
    depth_noise_var: 0.01
    maskout: True
    bg_value: 0


encoder_mode: "default"
cost_fn: "trajectory_return"

logger_name: "pick_and_place_fabric_single_task_logger"


datasets:
  - key: 'train'
    name: 'fabric-pick-and-place'
    params:
      random_seed: 0
      data_dir: 'draper_data/realadapt-towels-for-planet-clothpick'
      num_episodes: 1000
      raw_img_dim: [128, 128]
      cross_traj: True
      return_pick_and_place_action_z: False
      return_rgb: True
      swap_action: True #True
      return_depth: True
      return_mask: True
      sequence_len: 50
      action_horizon: 19
      episode_len: 19
      mode: 'train'
      reward_mode: "hoque_ddpg"
      flatten_bonus: 0.5
      penalise_action_threshold: 0.7
      extreme_action_penalty: -0.5
      misgrasping_penalty: -0.5
      unflatten_penalty: -0.5
      unflatten_threshold: 0.98
      misgrasping_threshold: 1.0
      flattening_threshold: 0.98
      eval_action_horizon: 19


  - key: 'test'
    name: 'fabric-pick-and-place'
    params:
      random_seed: 0
      data_dir: 'draper_data/realadapt-towels-for-planet-clothpick'
      num_episodes: 10
      raw_img_dim: [128, 128]
      cross_traj: True
      return_pick_and_place_action_z: False
      return_rgb: True
      return_depth: True
      swap_action: True
      return_mask: True
      sequence_len: 50
      action_horizon: 19
      episode_len: 19
      mode: 'eval'
      flatten_bonus: 0.5
      penalise_action_threshold: 0.7
      extreme_action_penalty: -0.5
      misgrasping_penalty: -0.5
      unflatten_penalty: -0.5
      unflatten_threshold: 0.98
      misgrasping_threshold: 1.0
      flattening_threshold: 0.98
      eval_action_horizon: 19

    

policy:
  name: 'rect_fabric_cloth_mask_mpc'
  params:
    candidates: 5000
    planning_horizon: 1
    iterations: 100
    clip: True
    cloth_mask: "from_env"
    swap_action: False
    cost_fn: 'from_model'


test_horizons: [1, 2, 4] # This shoulud be smaller than action horizon.
action_horizon: 50
eval_episodes: 10
eval_save_latent: True
eval_action_horizon: 19