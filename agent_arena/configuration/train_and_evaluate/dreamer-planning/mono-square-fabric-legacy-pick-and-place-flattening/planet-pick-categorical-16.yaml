
device: "cuda:0"
grayscale: False
size: [64, 64]
channels: 3
num_actions: 4
test_interval: 1000

# Model
dyn_cell: 'gru'
dyn_hidden: 200
dyn_deter: 200
dyn_stoch: 30
dyn_discrete: 16 ## Changes Here
dyn_input_layers: 1
dyn_output_layers: 1
dyn_trans_layers: 1
dyn_rec_depth: 1
dyn_shared: False
dyn_mean_act: 'none'
dyn_std_act: 'softplus'
dyn_min_std: 0.1
dyn_temp_post: True
grad_heads: ['image', 'reward']
units: 200
reward_layers: 2
act: "relu"
cnn_depth: 32
encoder_kernels: [4, 4, 4, 4]
decoder_kernels: [5, 5, 6, 6]
value_head: 'normal'
kl_scale: 1.0
kl_balance: 0.8
kl_free: 1.0
kl_forward: False
pred_discount: False
discount_scale: 1.0
reward_scale: 1.0
weight_decay: 0.0
decoder_thin: True
reward_gradient_stop: False

# Overshooting
overshooting_kl_scale: 0.1
overshooting_kl_balance: 1.0
overshooting_kl_free: 1.0
overshooting_kl_forward: False
overshooting_reward_scale: 0.1
overshooting_observation_scale: 0
overshooting_distance: 2
kl_overshooting_warmup: True
reward_overshooting_warmup: False


# Training
no_op: [0.5, 0.5, 0.5, 0.5]
batch_size: 50
sequence_size : 50
model_lr: 1e-3
opt_eps: 1e-4
grad_clip: 1000
opt: 'adam'
clip_rewards: 'identity'
update_steps: 100001
decoder_output_mode: 'deterministic'
reward_output_mode: 'deterministic'
reward_loss: 'mse' # Dreamer: 'nll'
decoder_loss: 'mse' # Dreamer: 'nll'


# Test
test_horizons: [1, 2, 4, 12]
action_horizon: 50
eval_episodes: 100

dataset: 
  name: 'mono-square-fabric-legacy-pick-and-place-flattening'
  params:
    num_episodes: 20000
    return_img_dim: [64, 64]
    cross_traj: True

transform:
  name: 'pick_and_place_transformer'
  params:
    device: "cuda:0"
    bit_depth: 5
    rgb_noise_var: 1.0
    random_terminal: False
    random_rotation: True
    rotation_degree: 90
    vertical_flip: True
    random_resize: False
    action_noise: 0.0