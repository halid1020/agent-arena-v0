update_steps: 100001
device: "cuda:0"
grayscale: False
size: [64, 64]
channels: 3
num_actions: 4
test_interval: 1000

# Model
dyn_cell: 'gru_layer_norm'
dyn_hidden: 600
dyn_deter: 600
dyn_stoch: 32
dyn_discrete: 32
dyn_input_layers: 1
dyn_output_layers: 1
dyn_rec_depth: 1
dyn_shared: False
dyn_mean_act: 'none'
dyn_std_act: 'sigmoid2'
dyn_min_std: 0.1
dyn_temp_post: True
grad_heads: ['image', 'reward']
units: 400
reward_layers: 4
act: "elu"
cnn_depth: 48
encoder_kernels: [4, 4, 4, 4]
decoder_kernels: [5, 5, 6, 6]
value_head: 'normal'
kl_scale: 1.0
kl_balance: 0.8
kl_free: 1.0
kl_forward: False
pred_discount: False
discount_scale: 1.0
reward_scale: 1.0
weight_decay: 1e-6
decoder_thin: True
reward_gradient_stop: True
decoder_output_mode: 'stochastic'
decoder_loss: 'nll'
reward_output_mode: 'stochastic'
reward_loss: 'nll'

overshooting_kl_scale: 0.1
overshooting_kl_balance: 1.0
overshooting_kl_free: 1.0
overshooting_kl_forward: False
overshooting_reward_scale: 0.1
overshooting_observation_scale: 0
overshooting_distance: 2
kl_overshooting_warmup: True
reward_overshooting_warmup: False


# Training
batch_size: 50
sequence_size : 50
model_lr: 2e-4
opt_eps: 1e-5
grad_clip: 100
opt: 'adam'
clip_rewards: 'tanh'

no_op: [0.5, 0.5, 0.5, 0.5]
test_horizons: [1, 2, 4, 12]
action_horizon: 50
eval_episodes: 100

dataset: 
  name: 'mono-square-fabric-legacy-pick-and-place-flattening'
  params:
    num_episodes: 20000
    return_img_dim: [64, 64]
    cross_traj: True

transform:
  name: 'pick_and_place_transformer'
  params:
    device: "cuda:0"
    bit_depth: 5
    rgb_noise_var: 1.0
    random_rotation: True
    random_terminal: False
    rotation_degree: 90
    vertical_flip: True
    random_resize: False
    action_noise: 0.0