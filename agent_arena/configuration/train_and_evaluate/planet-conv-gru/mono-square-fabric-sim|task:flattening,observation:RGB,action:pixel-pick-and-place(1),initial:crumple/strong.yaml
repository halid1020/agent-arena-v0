device: 'cuda:0'

belief_channel: 4
state_channel: 1
action_dim: 4
hidden_channel: 32
feature_map_dim: [8, 8]
obs_embedding_channel: 4
act_embedding_channel: 4
min_std_dev: 0.1
activation: 'relu'
trans_layers: 1
observation_dim: [3, 64, 64]
no_op: [1, 1, 1, 1]
free_nats: 1
symlog: False

rgb_observation_scale: 1.0
reward_scale: 1.0
reward_gradient_stop: False
kl_balance: 0.8
kl_scale: 1.0

overshooting_distance: 2  
kl_overshooting_scale: 0.1
kl_overshooting_warmup: True
kl_overshooting_balance: 1.0
reward_overshooting_scale: 0.1
reward_overshooting_warmup: False

## Reward Model
reward_num_conv_layers: 3
reward_hidden_channels: [32, 16, 4]
reward_conv_kernel_sizes: [3, 3, 3]
reward_conv_strides: [1, 1, 1]
reward_conv_paddings: [1, 1, 1]
reward_num_linear_layers: 2
reward_linear_hidden_dims: [200, 200]

## Image Encoder
image_encoder_num_conv_layers: 4
image_encoder_hidden_channel: [32, 64, 128, 256]
image_encoder_kernel_size: [4, 4, 4, 4, 3]
image_encoder_stride: [2, 2, 2, 2, 1]
image_encoder_padding: [0, 0, 0, 0, 1]

## Image Decoder
image_decoder_num_conv_layers: 3
image_decoder_hidden_channel: [128, 64, 32]
image_decoder_kernel_size: [5, 5, 6, 6]
image_decoder_stride: [2, 2, 2, 2]
image_decoder_padding: [0, 0, 0, 0]

## Action Encoder
action_encoder_num_layers: 2
action_encoder_hidden_channel: [32, 32]
action_encoder_kernel_size: [5, 5, 6]
action_encoder_stride: [2, 2, 2]
action_encoder_padding: [0, 0, 0]




optimiser_class: 'adam'
optimiser_params: 
  lr: 1e-3
  eps: 1e-4
grad_clip_norm: 1000

batch_size: 16
sequence_size: 20
update_steps: 200001
test_interval: 10000

datasets:
  - key: 'train'

    name: 'mono-square-fabric-pick-and-place'
    params:
      random_seed: 0
      num_episodes: 50000
      img_dim: [64, 64]
      cross_traj: True
      return_pick_and_place_action_z: False
      return_rgb: True
      return_depth: False
      sequence_len: 20
      action_horizon: 20
      episode_len: 20
      mode: 'train'
      reward_mode: "hoque_ddpg"
      flatten_bonus: 0.5
      penalise_action_threshold: 0.7
      extreme_action_penalty: -0.5
      misgrasping_penalty: -0.5
      unflatten_penalty: -0.5
      unflatten_threshold: 0.98
      misgrasping_threshold: 1.0
      flattening_threshold: 0.98


    transform:
      name: 'pick_and_place_transformer'
      params:
        remap_image: [-0.5, 0.5]
        device: "cuda:0"
        bit_depth: 5
        rgb_noise_var: 1.0
        random_rotation: True
        random_terminal: False
        rotation_degree: 90
        vertical_flip: True
        random_resize: False
        action_noise: 0.0
        reward_scale: 1.0
  
  - key: 'test'

    name: 'mono-square-fabric-pick-and-place'
    params:
      
      random_seed: 0
      num_episodes: 100
      img_dim: [64, 64]
      cross_traj: True
      return_pick_and_place_action_z: False
      return_rgb: True
      return_depth: False
      sequence_len: 20
      action_horizon: 20
      episode_len: 20
      mode: 'test'
      reward_mode: "hoque_ddpg"
      flatten_bonus: 0.5
      penalise_action_threshold: 0.7
      extreme_action_penalty: -0.5
      misgrasping_penalty: -0.5
      unflatten_penalty: -0.5
      unflatten_threshold: 0.98
      misgrasping_threshold: 1.0
      flattening_threshold: 0.98
    
    transform:
      name: 'pick_and_place_transformer'
      params:
        remap_image: [-0.5, 0.5]
        device: "cuda:0"
        bit_depth: 5
        rgb_noise_var: 0
        random_rotation: False
        random_terminal: False
        rotation_degree: 0
        vertical_flip: False
        random_resize: False

policy:
  name: 'rect_fabric_mpc_readjust_pick'
  params:
    action_lower_bound: -1
    action_upper_bound: 1

    candidates: 5000
    planning_horizon: 1
    iterations: 100
    action_dim: [1, 4]
    clip: True


    readjust_pick: True,
    readjust_pick_threshold: 0.1
    flatten_threshold: 0.98
    no_op: [1.0, 1.0, 1.0, 1.0]
    conservative_place: 1.0

    cost_fn: 'from_model'


test_horizons: [1, 2, 4] # This shoulud be smaller than action horizon.
action_horizon: 50
eval_episodes: 100